# -*- coding: utf-8 -*-
"""PneumoniaTracker.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tjixCod9PITRt_8XNuLHq5FsFyTPDd_D
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn
from pathlib import Path
from google.colab import files
import os
import zipfile
import torchvision
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from matplotlib.image import imread
from matplotlib import pyplot as plt
import time

path = Path('/root/.kaggle/kaggle.json')
if path.exists():
  print("File already exists")
else:
  files.upload()
  os.mkdir("/root/.kaggle/")
  os.rename("kaggle.json", path)

database_Path = Path("/dataset/chest_xray")

if database_Path.exists():
  print("File already exists ")
else:
  !kaggle datasets download -d paultimothymooney/chest-xray-pneumonia
  with zipfile.ZipFile("chest-xray-pneumonia.zip", "r") as zip_ref:
    zip_ref.extractall("/dataset")

torch.manual_seed(42)
device = "cuda" if torch.cuda.is_available() else "cpu"
device

my_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(degrees=15),
    transforms.RandomAffine(degrees=0, translate = None, scale=(0.9,1.1), shear=None),
    transforms.RandomCrop(size = (224, 224)),
    transforms.RandomGrayscale(p=0.2),
    transforms.ColorJitter(contrast=0.2),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

train_dataset = datasets.ImageFolder(root="/dataset/chest_xray/train", transform=my_transforms)
test_dataset = datasets.ImageFolder(root="/dataset/chest_xray/test", transform=my_transforms)
val_dataset = datasets.ImageFolder(root="/dataset/chest_xray/val", transform=my_transforms)

train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)
val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True)

imread("/dataset/chest_xray/train/NORMAL/IM-0115-0001.jpeg")
plt.imshow(imread("/dataset/chest_xray/train/NORMAL/IM-0115-0001.jpeg"))

class XrayModel(nn.Module):
    def __init__(self, num_classes=2):  # Assuming binary classification (Normal/Pneumonia)
        super(XrayModel, self).__init__()

        # Feature Extraction Layers:
        self.features = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(64),
            nn.MaxPool2d(kernel_size=2, stride=2),

            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(128),
            nn.MaxPool2d(kernel_size=2, stride=2),

            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(256),
            nn.MaxPool2d(kernel_size=2, stride=2),

            nn.Conv2d(256, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(512),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )

        # Classification Layers:
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),  # Global Average Pooling
            nn.Flatten(),
            nn.Linear(512, 256),  # Adjust hidden size as needed
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),  # Add dropout for regularization
            nn.Linear(256, num_classes),
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x

model = XrayModel().to(device)
loss = nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix


def calculate_metrics(y_true, y_pred):
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    conf_matrix = confusion_matrix(y_true, y_pred)

    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1-score: {f1:.4f}")
    print(f"Confusion Matrix:\n{conf_matrix}")

    return accuracy, precision, recall, f1, conf_matrix

# prompt: Create a Training/Testing Loop

# Training loop
epochs = 10  # Adjust as needed

for epoch in range(epochs):
    model.train()
    start_time = time.time()
    running_loss = 0.0

    for i, data in enumerate(train_dataloader, 0):
        inputs, labels = data[0].to(device), data[1].to(device)
        labels = labels.unsqueeze(1).float()

        optimizer.zero_grad()
        outputs = model(inputs)
        loss_value = loss(outputs, labels.float())
        loss_value.backward()
        optimizer.step()

        running_loss += loss_value.item()

    end_time = time.time()

    epoch_loss = running_loss / len(train_dataloader)
    print(f"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss:.4f}, Time: {end_time - start_time:.2f}s")

    # Validation
    model.eval()
    y_true_val = []
    y_pred_val = []

    with torch.no_grad():
      for inputs, labels in val_dataloader:
          inputs, labels = inputs.to(device), labels.to(device)
          outputs = model(inputs)
          _, predicted = torch.max(outputs, 1)

          y_true_val.extend(labels.cpu().numpy())
          y_pred_val.extend(predicted.cpu().numpy())

    val_accuracy, val_precision, val_recall, val_f1, _ = calculate_metrics(y_true_val, y_pred_val)
    print(f"Validation Accuracy: {val_accuracy:.4f}")

    scheduler.step()

# Testing
model.eval()
y_true_test = []
y_pred_test = []
with torch.no_grad():
    for inputs, labels in test_dataloader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)

        y_true_test.extend(labels.cpu().numpy())
        y_pred_test.extend(predicted.cpu().numpy())

test_accuracy, test_precision, test_recall, test_f1, conf_matrix = calculate_metrics(y_true_test, y_pred_test)
print(f"Test Accuracy: {test_accuracy:.4f}")